<!DOCTYPE html>
<html>
<head>
    

    

    



    <meta charset="utf-8">
    
    
    
    <title>Multiclass_logistic_regression | Prime&#39;s Blog | 弱菜的进化~</title>
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    
    <meta name="theme-color" content="#3F51B5">
    
    
    <meta name="keywords" content="machine_learning">
    <meta name="description" content="深度学习多分类问题，logistics regression模型，使用mnist数据集。">
<meta name="keywords" content="machine_learning">
<meta property="og:type" content="article">
<meta property="og:title" content="Multiclass_logistic_regression">
<meta property="og:url" content="https://www.prime666.com/2018/02/26/Multiclass-logistic-regression/index.html">
<meta property="og:site_name" content="Prime&#39;s Blog">
<meta property="og:description" content="深度学习多分类问题，logistics regression模型，使用mnist数据集。">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="https://github.com/zackchase/mxnet-the-straight-dope/blob/master/img/simple-softmax-net.png?raw=true">
<meta property="og:updated_time" content="2018-02-26T09:12:09.644Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Multiclass_logistic_regression">
<meta name="twitter:description" content="深度学习多分类问题，logistics regression模型，使用mnist数据集。">
<meta name="twitter:image" content="https://github.com/zackchase/mxnet-the-straight-dope/blob/master/img/simple-softmax-net.png?raw=true">
    
    <link rel="shortcut icon" href="/favicon/12.ico">
    <link rel="stylesheet" href="//unpkg.com/hexo-theme-material-indigo@latest/css/style.css">
    <script>window.lazyScripts=[]</script>

    <!-- custom head -->
    

</head>

<body>
    <div id="loading" class="active"></div>

    <aside id="menu" class="hide" >
  <div class="inner flex-row-vertical">
    <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="menu-off">
        <i class="icon icon-lg icon-close"></i>
    </a>
    <div class="brand-wrap" style="background-image:url(/img/brand.jpg)">
      <div class="brand">
        <a href="/" class="avatar waves-effect waves-circle waves-light">
          <img src="/avatar/class-act.png">
        </a>
        <hgroup class="introduce">
          <h5 class="nickname">Prime</h5>
          <a href="mailto:yuanma2017@outlook.com" title="yuanma2017@outlook.com" class="mail">yuanma2017@outlook.com</a>
        </hgroup>
      </div>
    </div>
    <div class="scroll-wrap flex-col">
      <ul class="nav">
        
            <li class="waves-block waves-effect">
              <a href="/"  >
                <i class="icon icon-lg icon-home"></i>
                主页
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/archives"  >
                <i class="icon icon-lg icon-archives"></i>
                Archives
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/tags"  >
                <i class="icon icon-lg icon-tags"></i>
                Tags
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/categories"  >
                <i class="icon icon-lg icon-th-list"></i>
                Categories
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="https://github.com/Neutral-network" target="_blank" >
                <i class="icon icon-lg icon-github"></i>
                Github
              </a>
            </li>
        
      </ul>
    </div>
  </div>
</aside>

    <main id="main">
        <header class="top-header" id="header">
    <div class="flex-row">
        <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light on" id="menu-toggle">
          <i class="icon icon-lg icon-navicon"></i>
        </a>
        <div class="flex-col header-title ellipsis">Multiclass_logistic_regression</div>
        
        <div class="search-wrap" id="search-wrap">
            <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="back">
                <i class="icon icon-lg icon-chevron-left"></i>
            </a>
            <input type="text" id="key" class="search-input" autocomplete="off" placeholder="Search">
            <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="search">
                <i class="icon icon-lg icon-search"></i>
            </a>
        </div>
        
        
    </div>
</header>
<header class="content-header post-header">

    <div class="container fade-scale">
        <h1 class="title">Multiclass_logistic_regression</h1>
        <h5 class="subtitle">
            
                <time datetime="2018-02-26T03:26:16.000Z" itemprop="datePublished" class="page-time">
  2018-02-26
</time>


	<ul class="article-category-list"><li class="article-category-list-item"><a class="article-category-list-link" href="/categories/AI/">AI</a></li></ul>

            
        </h5>
    </div>

    


</header>


<div class="container body-wrap">
    
    <aside class="post-widget">
        <nav class="post-toc-wrap post-toc-shrink" id="post-toc">
            <h4>TOC</h4>
            <ol class="post-toc"><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#scratch"><span class="post-toc-number">1.</span> <span class="post-toc-text">scratch</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#gluon"><span class="post-toc-number">2.</span> <span class="post-toc-text">gluon</span></a></li></ol>
        </nav>
    </aside>


<article id="post-Multiclass-logistic-regression"
  class="post-article article-type-post fade" itemprop="blogPost">

    <div class="post-card">
        <h1 class="post-card-title">Multiclass_logistic_regression</h1>
        <div class="post-meta">
            <time class="post-time" title="2018-02-26 11:26:16" datetime="2018-02-26T03:26:16.000Z"  itemprop="datePublished">2018-02-26</time>

            
	<ul class="article-category-list"><li class="article-category-list-item"><a class="article-category-list-link" href="/categories/AI/">AI</a></li></ul>



            
<span id="busuanzi_container_page_pv" title="文章总阅读量" style='display:none'>
    <i class="icon icon-eye icon-pr"></i><span id="busuanzi_value_page_pv"></span>
</span>


        </div>
        <div class="post-content" id="post-content" itemprop="postContent">
            <p>深度学习多分类问题，logistics regression模型，使用mnist数据集。</p>
<a id="more"></a>
<p>#Multiclass logistic regression</p>
<p>Given $k$ classes, the most naive way to solve a <strong><em>multiclass classification</em></strong> problem is to train $k$ different binary classifiers $f_i(x)$.There’s a smarter way to go about this. We could force the output layer to be a discrete probability distribution over the $k$ classes.</p>
<p>We accomplish this by using the <strong><em>softmax</em> function</strong>. Given an input vector $z$, softmax does two things. First, it exponentiates (elementwise) $e^z$, forcing all values to be strictly positive. Then it normalizes so that all values sum to 1.<br>$$<br>\text{softmax}(\boldsymbol{z}) = \frac{e^{\boldsymbol{z}} }{\sum_{i=1}^k e^{z_i}}<br>$$<br>Because now we have $k$ outputs and not 1 we’ll need weights connecting each of our inputs to each of our outputs. Graphically, the network looks something like this:</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://github.com/zackchase/mxnet-the-straight-dope/blob/master/img/simple-softmax-net.png?raw=true" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>We generate the linear mapping from inputs to outputs via a matrix-vector product $\boldsymbol{x}W+\boldsymbol{b}$.</p>
<p>The whole model, including the activation function can be written:<br>$$<br>\hat{y} = \text{softmax}(\boldsymbol{x} W + \boldsymbol{b})<br>$$<br>This model is sometimes called <em>multiclass logistic regression</em>. Other common names for it include <em>softmax regression</em> and <em>multinomial regression</em>.</p>
<p>##About batch training</p>
<p>In the above, we used plain lowercase letters for scalar variables, bolded lowercase letters for <strong>row</strong> vectors, and uppercase letters for matrices.</p>
<p> Assume we have $d$ inputs and $k$ outputs. Let’s note the shapes of the various variables explicitly as follows:<br>$$<br>\underset{1 \times k}{\boldsymbol z} = \underset{1 \times d}{\boldsymbol{x}}\ \underset{d \times k}{W} + \underset{1 \times k}{\boldsymbol{b}}<br>$$<br>Often we would one-hot encode the output label. So $\hat{y} = \text{softmax}(\boldsymbol z)$ becomes:<br>$$<br>\underset{1 \times k}{\boldsymbol{\hat{y}}<em>{one-hot}} = \text{softmax}</em>{one-hot}(\underset{1 \times k}{\boldsymbol z})<br>$$<br>When we input a batch of $m$ training examples, we would have matrix $\underset{m \times d}{X}$ that is the vertical stacking of individual training examples $\boldsymbol x_i$, due to the choice of using row vectors.<br>$$<br>\begin{split}X=<br>\begin{bmatrix}<br>    \boldsymbol x_1 \<br>    \boldsymbol x_2 \<br>    \vdots \<br>    \boldsymbol x<em>m<br>\end{bmatrix}<br>=<br>\begin{bmatrix}<br>    x</em>{11} &amp; x<em>{12} &amp; x</em>{13} &amp; \dots  &amp; x<em>{1d} \<br>    x</em>{21} &amp; x<em>{22} &amp; x</em>{23} &amp; \dots  &amp; x<em>{2d} \<br>    \vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots \<br>    x</em>{m1} &amp; x<em>{m2} &amp; x</em>{m3} &amp; \dots  &amp; x<em>{md}<br>\end{bmatrix}\end{split}<br>$$<br>${\boldsymbol{\hat{y}}</em>{one-hot}} = \text{softmax}({\boldsymbol z})$turns into:<br>$$<br>Y = \text{softmax}(Z) = \text{softmax}(XW + B)<br>$$<br>这里$B$是m*k矩阵，其相当于$\boldsymbol{b}$的m次拷贝，如下图所示：<br>$$<br>\begin{split} B =<br>\begin{bmatrix}<br>    \boldsymbol b \<br>    \boldsymbol b \<br>    \vdots \<br>    \boldsymbol b<br>\end{bmatrix}<br>=<br>\begin{bmatrix}<br>    b<em>{1} &amp; b</em>{2} &amp; b<em>{3} &amp; \dots  &amp; b</em>{k} \<br>    b<em>{1} &amp; b</em>{2} &amp; b<em>{3} &amp; \dots  &amp; b</em>{k} \<br>    \vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots \<br>    b<em>{1} &amp; b</em>{2} &amp; b<em>{3} &amp; \dots  &amp; b</em>{k}<br>\end{bmatrix}\end{split}<br>$$<br>显然，可以通过broadcasting来直接使用$\boldsymbol{b}$。</p>
<p>Each row of matrix $\underset{m \times k}{Z}$ corresponds to one training example. The softmax function operates on each row of matrix $Z$ and returns a matrix $\underset{m \times k}{Y}$, each row of which corresponds to the one-hot encoded prediction of one training example.</p>
<p>##The MNIST dataset</p>
<p>This time we’re going to work with real data, each a 28 by 28 centrally cropped（裁剪） black &amp; white photograph of a handwritten digit. Our task will be come up with a model that can associate each image with the digit (0-9) that it depicts.</p>
<p>##The cross-entropy loss function</p>
<p>The relevant loss function here is called <strong>cross-entropy</strong> and it may be the most common loss function you’ll find in all of deep learning. That’s because at the moment, classification problems tend to be far more abundant than regression problems.</p>
<p>The basic idea is that we’re going to take a target Y that has been formatted as a one-hot vector, meaning one value corresponding to the correct label is set to 1 and the others are set to 0, e.g.<code>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0]</code>.</p>
<p>The basic idea of cross-entropy loss is that we only care about how much probability the prediction assigned to the correct label. In other words, for true label 2, we only care about the component of yhat corresponding to 2</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">cross_entropy</span><span class="params">(yhat, y)</span>:</span></div><div class="line">    <span class="keyword">return</span> - nd.sum(y * nd.log(yhat+<span class="number">1e-6</span>))</div></pre></td></tr></table></figure>
<p> MXNet’s has an efficient function that <u>simultaneously computes the softmax activation and cross-entropy loss</u>. However, if ever need to get the output probabilities,</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">softmax_cross_entropy = gluon.loss.SoftmaxCrossEntropyLoss()</div></pre></td></tr></table></figure>
<h2 id="scratch"><a href="#scratch" class="headerlink" title="scratch"></a>scratch</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">import</span> mxnet <span class="keyword">as</span> mx</div><div class="line"><span class="keyword">from</span> mxnet <span class="keyword">import</span> nd, autograd, gluon</div><div class="line"><span class="keyword">from</span> utils <span class="keyword">import</span> SGD</div><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line"><span class="keyword">import</span> time</div><div class="line"></div><div class="line">start_time = time.time()</div><div class="line"></div><div class="line">mx.random.seed(<span class="number">1</span>)</div><div class="line"></div><div class="line">data_ctx = mx.gpu(<span class="number">0</span>)</div><div class="line">model_ctx = mx.gpu(<span class="number">0</span>)</div><div class="line"></div><div class="line">num_inputs = <span class="number">784</span>  <span class="comment"># 28 * 28</span></div><div class="line">num_outputs = <span class="number">10</span></div><div class="line">num_examples = <span class="number">60000</span></div><div class="line"></div><div class="line">W = nd.random_normal(shape=(num_inputs, num_outputs), ctx=model_ctx)</div><div class="line"></div><div class="line">b = nd.random_normal(shape=num_outputs, ctx=model_ctx)</div><div class="line"></div><div class="line">params = [W, b]</div><div class="line"></div><div class="line"><span class="keyword">for</span> param <span class="keyword">in</span> params:</div><div class="line">    param.attach_grad()</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">transform</span><span class="params">(data, label)</span>:</span></div><div class="line">    <span class="comment"># cast data and label to floats and normalize data to range [0, 1]</span></div><div class="line">    <span class="keyword">return</span> data.astype(np.float32)/<span class="number">255</span>, label.astype(np.float32)</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">softmax</span><span class="params">(y_linear)</span>:</span></div><div class="line">    exp = nd.exp(y_linear-nd.max(y_linear, axis=<span class="number">1</span>).reshape((<span class="number">-1</span>, <span class="number">1</span>)))</div><div class="line">    norms = nd.sum(exp, axis=<span class="number">1</span>).reshape((<span class="number">-1</span>, <span class="number">1</span>))</div><div class="line">    <span class="keyword">return</span> exp / norms  <span class="comment"># 矩阵除以列向量，矩阵每一行除以列向量norms的每一行元素。</span></div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">net</span><span class="params">(X)</span>:</span></div><div class="line">    y_linear = nd.dot(X, W) + b</div><div class="line">    yhat = softmax(y_linear)</div><div class="line">    <span class="keyword">return</span> yhat</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">cross_entropy</span><span class="params">(yhat, y)</span>:</span></div><div class="line">    <span class="keyword">return</span> - nd.sum(y * nd.log(yhat+<span class="number">1e-6</span>))</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">evaluate_accuracy</span><span class="params">(data_iterator, net)</span>:</span></div><div class="line">    <span class="comment"># 计算精确度</span></div><div class="line">    numerator = <span class="number">0.</span>  <span class="comment"># 分子</span></div><div class="line">    denominator = <span class="number">0.</span>  <span class="comment"># 分母</span></div><div class="line">    <span class="keyword">for</span> i, (data, label) <span class="keyword">in</span> enumerate(data_iterator):</div><div class="line">        data = data.as_in_context(model_ctx).reshape((<span class="number">-1</span>, <span class="number">784</span>))</div><div class="line">        label = label.as_in_context(model_ctx)</div><div class="line">        <span class="comment"># label_one_hot = nd.one_hot(label, 10)</span></div><div class="line">        output = net(data)</div><div class="line">        predictions = nd.argmax(output, axis=<span class="number">1</span>)</div><div class="line">        numerator += nd.sum(predictions == label)</div><div class="line">        denominator += data.shape[<span class="number">0</span>]</div><div class="line">    <span class="keyword">return</span> (numerator / denominator).asscalar()</div><div class="line"></div><div class="line"></div><div class="line">mnist_train = gluon.data.vision.MNIST(root=<span class="string">'../data_set/mnist'</span>, train=<span class="keyword">True</span>, transform=transform)</div><div class="line">mnist_test = gluon.data.vision.MNIST(root=<span class="string">'../data_set/mnist'</span>, train=<span class="keyword">False</span>, transform=transform)</div><div class="line"></div><div class="line"><span class="string">'''</span></div><div class="line"># each item is a tuple of an image(28*28) and a label</div><div class="line">image, label = mnist_train[0]</div><div class="line">print(type(image))</div><div class="line">print(image.shape, label)  # 28 * 28 * 1</div><div class="line"></div><div class="line">im = mx.nd.tile(image, (1, 1, 3))  # 把图片按照第三维broadcast，这样matplotlib才能画图</div><div class="line">print(im.shape)</div><div class="line"></div><div class="line">plt.imshow(im.asnumpy())</div><div class="line">plt.show()</div><div class="line">'''</div><div class="line"></div><div class="line"></div><div class="line">batch_size = <span class="number">64</span></div><div class="line">train_data = mx.gluon.data.DataLoader(mnist_train, batch_size, shuffle=<span class="keyword">True</span>)</div><div class="line"></div><div class="line">test_data = mx.gluon.data.DataLoader(mnist_test, batch_size, shuffle=<span class="keyword">False</span>)</div><div class="line"></div><div class="line"></div><div class="line">epochs = <span class="number">20</span></div><div class="line">learning_rate = <span class="number">.005</span></div><div class="line"></div><div class="line"><span class="keyword">for</span> e <span class="keyword">in</span> range(epochs):</div><div class="line">    cumulative_loss = <span class="number">0</span></div><div class="line">    <span class="keyword">for</span> i, (data, label) <span class="keyword">in</span> enumerate(train_data):</div><div class="line">        data = data.as_in_context(model_ctx).reshape((<span class="number">-1</span>, <span class="number">784</span>))</div><div class="line">        label = label.as_in_context(model_ctx)</div><div class="line">        label_one_hot = nd.one_hot(label, <span class="number">10</span>)</div><div class="line">        <span class="keyword">with</span> autograd.record():</div><div class="line">            output = net(data)</div><div class="line">            loss = cross_entropy(output, label_one_hot)</div><div class="line">        loss.backward()</div><div class="line">        SGD(params, learning_rate)</div><div class="line">        cumulative_loss += nd.sum(loss).asscalar()</div><div class="line"></div><div class="line">    test_accuracy = evaluate_accuracy(test_data, net)</div><div class="line">    train_accuracy = evaluate_accuracy(train_data, net)</div><div class="line">    print(<span class="string">"Epoch &#123;&#125;. Loss: &#123;&#125;, Train_acc &#123;:%&#125;, Test_acc &#123;:%&#125;"</span>.format(e, cumulative_loss/num_examples, train_accuracy, test_accuracy))</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># Define the function to do prediction</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">model_predict</span><span class="params">(net, data)</span>:</span></div><div class="line">    output = net(data)</div><div class="line">    <span class="keyword">return</span> nd.argmax(output, axis=<span class="number">1</span>)</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># let's sample 10 random data points from the test set</span></div><div class="line">sample_data = mx.gluon.data.DataLoader(mnist_test, batch_size=<span class="number">10</span>, shuffle=<span class="keyword">True</span>)</div><div class="line"><span class="keyword">for</span> i, (data, label) <span class="keyword">in</span> enumerate(sample_data):</div><div class="line">    data = data.as_in_context(model_ctx)</div><div class="line">    print(data.shape)</div><div class="line">    im = nd.transpose(data, (<span class="number">1</span>, <span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>))</div><div class="line">    im = nd.reshape(im, (<span class="number">28</span>, <span class="number">10</span>*<span class="number">28</span>, <span class="number">1</span>))</div><div class="line">    imtiles = nd.tile(im, (<span class="number">1</span>, <span class="number">1</span>, <span class="number">3</span>))</div><div class="line">    print(imtiles.shape)</div><div class="line"></div><div class="line">    plt.imshow(imtiles.asnumpy())</div><div class="line">    plt.show()</div><div class="line">    pred = model_predict(net, data.reshape((<span class="number">-1</span>, <span class="number">784</span>)))</div><div class="line">    print(<span class="string">'model predictions are:'</span>, pred)</div><div class="line">    <span class="keyword">break</span></div><div class="line"></div><div class="line">end_time = time.time()</div><div class="line"></div><div class="line">print(<span class="string">'total time:%.0fs'</span> % (end_time-start_time))</div></pre></td></tr></table></figure>
<h2 id="gluon"><a href="#gluon" class="headerlink" title="gluon"></a>gluon</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> mxnet <span class="keyword">as</span> mx</div><div class="line"><span class="keyword">from</span> mxnet <span class="keyword">import</span> nd, autograd</div><div class="line"><span class="keyword">from</span> mxnet <span class="keyword">import</span> gluon</div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line"></div><div class="line">data_ctx = mx.gpu(<span class="number">0</span>)</div><div class="line">model_ctx = mx.gpu(<span class="number">0</span>)</div><div class="line"></div><div class="line">mx.random.seed(<span class="number">1</span>)</div><div class="line"></div><div class="line"></div><div class="line">batch_size = <span class="number">64</span></div><div class="line">num_inputs = <span class="number">784</span></div><div class="line">num_outputs = <span class="number">10</span></div><div class="line">num_examples = <span class="number">60000</span></div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">transform</span><span class="params">(data, label)</span>:</span></div><div class="line">    <span class="keyword">return</span> data.astype(np.float32)/<span class="number">255</span>, label.astype(np.float32)</div><div class="line"></div><div class="line"></div><div class="line">train_data = mx.gluon.data.DataLoader(mx.gluon.data.vision.MNIST(root=<span class="string">'../data_set/mnist'</span>, train=<span class="keyword">True</span>, transform=transform), batch_size, shuffle=<span class="keyword">True</span>)</div><div class="line">test_data = mx.gluon.data.DataLoader(mx.gluon.data.vision.MNIST(root=<span class="string">'../data_set/mnist'</span>, train=<span class="keyword">False</span>, transform=transform), batch_size, shuffle=<span class="keyword">False</span>)</div><div class="line"></div><div class="line">net = gluon.nn.Dense(num_outputs)</div><div class="line"></div><div class="line">net.collect_params().initialize(mx.init.Normal(sigma=<span class="number">1.</span>), ctx=model_ctx)</div><div class="line"></div><div class="line">softmax_cross_entropy = gluon.loss.SoftmaxCrossEntropyLoss()</div><div class="line"></div><div class="line">trainer = gluon.Trainer(net.collect_params(), <span class="string">'sgd'</span>, &#123;<span class="string">'learning_rate'</span>: <span class="number">0.1</span>&#125;)</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">evaluate_accuracy</span><span class="params">(data_iterator, net)</span>:</span></div><div class="line">    acc = mx.metric.Accuracy()</div><div class="line">    <span class="keyword">for</span> i, (data, label) <span class="keyword">in</span> enumerate(data_iterator):</div><div class="line">        data = data.as_in_context(model_ctx).reshape((<span class="number">-1</span>, <span class="number">784</span>))</div><div class="line">        label = label.as_in_context(model_ctx)</div><div class="line">        output = net(data)</div><div class="line">        predictions = nd.argmax(output, axis=<span class="number">1</span>)</div><div class="line">        acc.update(preds=predictions, labels=label)</div><div class="line">    <span class="keyword">return</span> acc.get()[<span class="number">1</span>]</div><div class="line"></div><div class="line"></div><div class="line">print(<span class="string">'未训练时精确度 %.2f'</span> % evaluate_accuracy(test_data, net))</div><div class="line"></div><div class="line">epochs = <span class="number">10</span></div><div class="line">moving_loss = <span class="number">0</span></div><div class="line"></div><div class="line"></div><div class="line"><span class="keyword">for</span> e <span class="keyword">in</span> range(epochs):</div><div class="line">    cumulative_loss = <span class="number">0</span></div><div class="line">    <span class="keyword">for</span> data, label <span class="keyword">in</span> train_data:</div><div class="line">        data = data.as_in_context(model_ctx).reshape((<span class="number">-1</span>, <span class="number">784</span>))</div><div class="line">        label = label.as_in_context(model_ctx)</div><div class="line">        <span class="keyword">with</span> autograd.record():</div><div class="line">            output = net(data)</div><div class="line">            loss = softmax_cross_entropy(output, label)</div><div class="line">        loss.backward()</div><div class="line">        trainer.step(batch_size)</div><div class="line">        cumulative_loss += nd.sum(loss).asscalar()</div><div class="line">    test_accuracy = evaluate_accuracy(test_data, net)</div><div class="line">    train_accuracy = evaluate_accuracy(train_data, net)</div><div class="line">    print(<span class="string">"Epoch &#123;&#125;. Loss: &#123;&#125;, Train_acc &#123;:%&#125;, Test_acc &#123;:%&#125;"</span>.format(e, cumulative_loss / num_examples, train_accuracy,</div><div class="line">                                                                     test_accuracy))</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">model_predict</span><span class="params">(net,data)</span>:</span></div><div class="line">    output = net(data.as_in_context(model_ctx))</div><div class="line">    <span class="keyword">return</span> nd.argmax(output, axis=<span class="number">1</span>)</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># let's sample 10 random data points from the test set</span></div><div class="line">sample_data = mx.gluon.data.DataLoader(mx.gluon.data.vision.MNIST(train=<span class="keyword">False</span>, transform=transform), <span class="number">10</span>, shuffle=<span class="keyword">True</span>)</div><div class="line"><span class="keyword">for</span> i, (data, label) <span class="keyword">in</span> enumerate(sample_data):</div><div class="line">    data = data.as_in_context(model_ctx)</div><div class="line">    print(data.shape)</div><div class="line">    im = nd.transpose(data, (<span class="number">1</span>, <span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>))</div><div class="line">    im = nd.reshape(im, (<span class="number">28</span>, <span class="number">10</span>*<span class="number">28</span>, <span class="number">1</span>))</div><div class="line">    imtiles = nd.tile(im, (<span class="number">1</span>, <span class="number">1</span>, <span class="number">3</span>))</div><div class="line"></div><div class="line">    plt.imshow(imtiles.asnumpy())</div><div class="line">    plt.show()</div><div class="line">    pred = model_predict(net, data.reshape((<span class="number">-1</span>, <span class="number">784</span>)))</div><div class="line">    print(<span class="string">'model predictions are:'</span>, pred)</div><div class="line">    <span class="keyword">break</span></div></pre></td></tr></table></figure>

        </div>

        <blockquote class="post-copyright">
    
    <div class="content">
        
<span class="post-time">
    Last updated: <time datetime="2018-02-26T09:12:09.644Z" itemprop="dateUpdated">2018-02-26 17:12:09</time>
</span><br>


        
        转载请注明出处
        
    </div>
    
    <footer>
        <a href="https://www.prime666.com">
            <img src="/avatar/class-act.png" alt="Prime">
            Prime
        </a>
    </footer>
</blockquote>

        


        <div class="post-footer">
            
	<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/machine-learning/">machine_learning</a></li></ul>


            


        </div>
    </div>

    
<nav class="post-nav flex-row flex-justify-between">
  
    <div class="waves-block waves-effect prev">
      <a href="/2018/02/27/Overfitting-and-regularization/" id="post-prev" class="post-nav-link">
        <div class="tips"><i class="icon icon-angle-left icon-lg icon-pr"></i> Prev</div>
        <h4 class="title">Overfitting and regularization</h4>
      </a>
    </div>
  

  
    <div class="waves-block waves-effect next">
      <a href="/2018/01/16/python第三方库用法/" id="post-next" class="post-nav-link">
        <div class="tips">Next <i class="icon icon-angle-right icon-lg icon-pl"></i></div>
        <h4 class="title">python第三方库用法</h4>
      </a>
    </div>
  
</nav>



    














</article>



</div>

        <footer class="footer">
    <div class="top">
        
<p>
    <span id="busuanzi_container_site_uv" style='display:none'>
        站点总访客数：<span id="busuanzi_value_site_uv"></span>
    </span>
    <span id="busuanzi_container_site_pv" style='display:none'>
        站点总访问量：<span id="busuanzi_value_site_pv"></span>
    </span>
</p>


        <p>
            
            <span>This blog is licensed under a <a rel="license" href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License</a>.</span>
        </p>
    </div>
    <div class="bottom">
        <p><span>Prime &copy; 2017 - 2018</span>
            <span>
                
                Power by <a href="http://hexo.io/" target="_blank">Hexo</a> 
            </span>
        </p>
    </div>
</footer>

    </main>
    <div class="mask" id="mask"></div>
<a href="javascript:;" id="gotop" class="waves-effect waves-circle waves-light"><span class="icon icon-lg icon-chevron-up"></span></a>


    <script src="//cdn.bootcss.com/node-waves/0.7.4/waves.min.js"></script>
<script>
var BLOG = { ROOT: '/', SHARE: false, REWARD: false };


</script>

<script src="//unpkg.com/hexo-theme-material-indigo@latest/js/main.min.js"></script>


<div class="search-panel" id="search-panel">
    <ul class="search-result" id="search-result"></ul>
</div>
<template id="search-tpl">
<li class="item">
    <a href="{path}" class="waves-block waves-effect">
        <div class="title ellipsis" title="{title}">{title}</div>
        <div class="flex-row flex-middle">
            <div class="tags ellipsis">
                {tags}
            </div>
            <time class="flex-col time">{date}</time>
        </div>
    </a>
</li>
</template>

<script src="//unpkg.com/hexo-theme-material-indigo@latest/js/search.min.js" async></script>



<!-- mathjax config similar to math.stackexchange -->

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
});
</script>

<script async src="//cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML" async></script>




<script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>



<script>
(function() {
    var OriginTitile = document.title, titleTime;
    document.addEventListener('visibilitychange', function() {
        if (document.hidden) {
            document.title = '○･｀Д´･○你要去哪里？';
            clearTimeout(titleTime);
        } else {
            document.title = '(つェ⊂)咦!又好了!';
            titleTime = setTimeout(function() {
                document.title = OriginTitile;
            },2000);
        }
    });
})();
</script>



</body>
</html>
